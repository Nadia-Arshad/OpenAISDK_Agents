{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNwid5JRufxx",
        "outputId": "bd34341e-7598-4e73-8fa6-806860624e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/120.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.2/120.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/130.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.4/720.4 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "LUOv3EhpvQYR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "gemini_api_key = userdata.get(\"GEMINI_NEW_KEY\")\n",
        "if gemini_api_key:\n",
        "  print(\"Yes\")\n",
        "else:\n",
        "  print(\"No\")\n",
        "\n",
        "client= AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    openai_client=client,\n",
        "    model=\"gemini-2.0-flash\"\n",
        ")\n",
        "\n",
        "config= RunConfig(\n",
        "    model_provider=client,\n",
        "    model=model,\n",
        "    tracing_disabled=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwXQHiNCumOF",
        "outputId": "cccd38c6-2505-4dea-d6e5-031512635a41"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from agents import Agent, Runner, handoff\n",
        "\n",
        "spanish_agent= Agent(\n",
        "    name=\"Alejandro\",\n",
        "    instructions=\"You will be answering questions asked in Spanish.\"\n",
        ")\n",
        "\n",
        "english_agent= Agent(\n",
        "    name=\"John\",\n",
        "    instructions=\"You will be answering questions asked in English.\"\n",
        ")\n",
        "\n",
        "triage_agent= Agent(\n",
        "    name=\"Manager\",\n",
        "    instructions=\"You need to delegate the request to the appropriate agent depending on the language.\",\n",
        "    handoffs= [spanish_agent, english_agent]\n",
        ")\n",
        "\n",
        "async def main(input: str):\n",
        "    result = await Runner.run(triage_agent, input=input, run_config=config)\n",
        "    print(result.final_output)\n",
        ""
      ],
      "metadata": {
        "id": "WDPkwdeCwKJ4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asyncio.run(main(\"¿Cómo estás?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGzJTP4XxSHc",
        "outputId": "52b0e0df-be12-4476-c561-e37bd7e9cd00"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Estoy muy bien, gracias! ¿Y tú?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "asyncio.run(main(\"Escribeme una poema sobre los nubes?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw4cOXXmxYxx",
        "outputId": "dcb5eaca-67aa-4ee1-9dda-b440828a670c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Alejandro:**\n",
            "\n",
            "Claro que sí, aquí te va un poema sobre las nubes:\n",
            "\n",
            "En lienzo azul, flotantes algodones,\n",
            "las nubes viajan, sin cesar, sin prisa.\n",
            "Blancos rebaños, cándidos borrones,\n",
            "pintando el cielo con sutil sonrisa.\n",
            "\n",
            "A veces torres, castillos de cristal,\n",
            "que el sol ilumina con dorado brillo.\n",
            "Otras, borrascas, presagio fatal,\n",
            "anunciando la tormenta, con sombrío sigilo.\n",
            "\n",
            "Se deforman, se estiran, se deshacen,\n",
            "camaleónicas, en danza sin igual.\n",
            "Cuentan historias, si es que las rehacen\n",
            "en sueños líquidos, de un mundo celestial.\n",
            "\n",
            "Espejos vagos de la imaginación,\n",
            "donde figuras surgen y se van.\n",
            "Un mágico teatro, en constante creación,\n",
            "las nubes, poetas del cielo que están.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "asyncio.run(main(\"Who is Donald Trump?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6RD_TjKxkaz",
        "outputId": "28f591f8-09a1-4449-8192-9ad403654b98"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Donald Trump is an American businessman, television personality, and politician who served as the 45th President of the United States from 2017 to 2021. Before entering politics, he was a real estate developer and media figure. He is a member of the Republican Party.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yBPQPHjuxsrs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}